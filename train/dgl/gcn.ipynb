{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs_data/zhanggh/miniconda3/envs/TVM_torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "from dgl.data import CoraGraphDataset, CiteseerGraphDataset, PubmedGraphDataset\n",
    "from dgl import AddSelfLoop\n",
    "import argparse\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_size, hid_size, out_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # two-layer GCN\n",
    "        self.layers.append(dglnn.GraphConv(in_size, hid_size, activation=F.relu))\n",
    "        self.layers.append(dglnn.GraphConv(hid_size, out_size))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = features\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                h = self.dropout(h)\n",
    "            h = layer(g, h)\n",
    "        return h\n",
    "    \n",
    "def evaluate(g, features, labels, mask, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "\n",
    "def train(g, features, labels, masks, model):\n",
    "    # define train/val samples, loss function and optimizer\n",
    "    train_mask = masks[0]\n",
    "    val_mask = masks[1]\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        logits = model(g, features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = evaluate(g, features, labels, val_mask, model)\n",
    "        print(\"Epoch {:05d} | Loss {:.4f} | Accuracy {:.4f} \"\n",
    "              . format(epoch, loss.item(), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 19717\n",
      "  NumEdges: 88651\n",
      "  NumFeats: 500\n",
      "  NumClasses: 3\n",
      "  NumTrainingSamples: 60\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Training...\n",
      "Epoch 00000 | Loss 1.0975 | Accuracy 0.5000 \n",
      "Epoch 00001 | Loss 1.0904 | Accuracy 0.6100 \n",
      "Epoch 00002 | Loss 1.0843 | Accuracy 0.6760 \n",
      "Epoch 00003 | Loss 1.0748 | Accuracy 0.5880 \n",
      "Epoch 00004 | Loss 1.0660 | Accuracy 0.6160 \n",
      "Epoch 00005 | Loss 1.0559 | Accuracy 0.6560 \n",
      "Epoch 00006 | Loss 1.0452 | Accuracy 0.6560 \n",
      "Epoch 00007 | Loss 1.0285 | Accuracy 0.6800 \n",
      "Epoch 00008 | Loss 1.0196 | Accuracy 0.6820 \n",
      "Epoch 00009 | Loss 1.0079 | Accuracy 0.6940 \n"
     ]
    }
   ],
   "source": [
    "from dgl.data import PubmedGraphDataset\n",
    "raw_dir = \"../data/dgl\"\n",
    "# load and preprocess dataset\n",
    "transform = AddSelfLoop()\n",
    "data = PubmedGraphDataset(raw_dir=raw_dir, transform=transform)\n",
    "g = data[0]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "g = g.int().to(device)\n",
    "features = g.ndata['feat']\n",
    "labels = g.ndata['label']\n",
    "masks = g.ndata['train_mask'], g.ndata['val_mask'], g.ndata['test_mask']\n",
    "    \n",
    "# normalization\n",
    "degs = g.in_degrees().float()\n",
    "norm = torch.pow(degs, -0.5).to(device)\n",
    "norm[torch.isinf(norm)] = 0\n",
    "g.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "# create GCN model    \n",
    "in_size = features.shape[1]\n",
    "out_size = data.num_classes\n",
    "model = GCN(in_size, 16, out_size).to(device)\n",
    "\n",
    "# model training\n",
    "print('Training...')\n",
    "train(g, features, labels, masks, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GraphConv(in=500, out=16, normalization=both, activation=<function relu at 0x7f304a0149d0>)\n",
      "    (1): GraphConv(in=16, out=3, normalization=both, activation=None)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "GraphConv\n",
      "both\n",
      "16\n",
      "500\n",
      "relu\n",
      "torch.Size([500, 16])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(model)\n",
    "print(model.layers[0].__class__.__name__)\n",
    "print(model.layers[0].__dict__['_norm'])\n",
    "print(model.layers[0].__dict__['_out_feats'])\n",
    "print(model.layers[0].__dict__['_in_feats'])\n",
    "print(model.layers[0].__dict__['_activation'].__name__)\n",
    "print(model.layers[0].state_dict()['weight'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_feature(g):\n",
    "    from math import log2, pow\n",
    "    shape = g.ndata['feat'].shape\n",
    "    feat_num = pow(2,int(log2(shape[1])) + 1)\n",
    "    g.ndata['feat'] = F.pad(g.ndata['feat'], (0,int(feat_num-shape[1])), \"constant\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 4096])\n",
      "torch.Size([2708, 4096])\n"
     ]
    }
   ],
   "source": [
    "tmp_g = g\n",
    "enlarge_feature(tmp_g)\n",
    "print(tmp_g.ndata['feat'].shape)\n",
    "print(g.ndata['feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feat', 'label', 'test_mask', 'train_mask', 'val_mask', 'norm'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 2708)\n",
      "(13264,)\n",
      "(13264,)\n",
      "(13264,)\n",
      "torch.Size([2708, 1])\n"
     ]
    }
   ],
   "source": [
    "coo_g = g.adjacency_matrix(scipy_fmt = 'coo')\n",
    "print(coo_g.shape)\n",
    "print(coo_g.row.shape)\n",
    "print(coo_g.col.shape)\n",
    "e_data = coo_g.data\n",
    "norm = g.ndata['norm']\n",
    "print(e_data.shape)\n",
    "print(norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13264, 1)\n"
     ]
    }
   ],
   "source": [
    "def copy_norm(edges):\n",
    "  return {'m': edges.dst['norm']}\n",
    "\n",
    "g.apply_edges(copy_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13264)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "agg_adj = g.edata['m'].cpu().numpy().transpose()\n",
    "print(agg_adj.shape)\n",
    "f = open(\"../trace/agg_adj.npy\", \"wb\")\n",
    "np.save(f, agg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13264)\n",
      "(2, 13264)\n"
     ]
    }
   ],
   "source": [
    "row_ids = np.expand_dims(coo_g.row, axis=0)\n",
    "col_ids = np.expand_dims(coo_g.col, axis=0)\n",
    "print(row_ids.shape)\n",
    "agg_index = np.concatenate((row_ids, col_ids), axis=0)\n",
    "print(agg_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6114,  1.4711, -0.7030],\n",
      "        [-1.7285, -0.8871, -1.7409],\n",
      "        [-0.8648,  0.5302, -0.9473],\n",
      "        [-3.4139,  0.2511,  1.7076],\n",
      "        [-1.4238,  0.4509,  2.3247],\n",
      "        [ 0.8083, -0.4484,  0.2525]])\n",
      "tensor([[-0.6114,  1.4711, -0.7030],\n",
      "        [-1.7285, -0.8871, -1.7409],\n",
      "        [-0.8648,  0.5302, -0.9473],\n",
      "        [-3.4139,  0.2511,  1.7076],\n",
      "        [-1.4238,  0.4509,  2.3247],\n",
      "        [ 0.8083, -0.4484,  0.2525]])\n",
      "tensor([ 0.0407,  0.2770, -0.6609, -0.0441, -2.1066])\n",
      "[0 0 0 0 0]\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "ng = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]), num_nodes=6)\n",
    "ng.ndata['x'] = torch.randn(6)\n",
    "feat = torch.randn(6,3)\n",
    "feat_src, feat_dst = dgl.utils.expand_as_pair(feat, ng)\n",
    "print(feat_src)\n",
    "print(feat_dst)\n",
    "def copy_x(edges):\n",
    "  return {'m': edges.dst['x']} # \"edge.dst\" is the opposite of \"graph.dstdata\"\n",
    "ng.apply_edges(copy_x)\n",
    "print(ng.edata['m'])\n",
    "coo_ng = ng.adjacency_matrix(scipy_fmt = 'coo') # It has a \"transpose\" parameter\n",
    "print(coo_ng.row)\n",
    "print(coo_ng.col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 2 3 3 3]\n",
      "[0 1 1 2 2 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "ng = dgl.graph(([0, 1, 0, 1, 2, 3, 3, 3], [0, 1, 1, 2, 2, 1, 2, 3]), num_nodes=4)\n",
    "# check the sparse array\n",
    "coo = ng.adjacency_matrix(scipy_fmt = 'coo')\n",
    "print(coo.row)\n",
    "print(coo.col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ld': tensor([0.5000, 0.5000, 0.5000, 1.0000, 1.0000, 0.5000, 1.0000, 0.3333]), 'ls': tensor([0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.3333, 0.3333, 0.3333]), 'rd': tensor([1.0000, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 1.0000]), 'rs': tensor([1.0000, 1.0000, 0.3333, 0.3333, 0.3333, 1.0000, 1.0000, 1.0000])}\n",
      "{'l_norm': tensor([0.5000, 0.5000, 1.0000, 0.3333]), 'r_norm': tensor([1.0000, 0.3333, 0.3333, 1.0000]), 'h': tensor([0.5000, 0.5000, 1.0000, 0.3333])}\n"
     ]
    }
   ],
   "source": [
    "# check the left and right norm\n",
    "out_degs = ng.out_degrees().float()\n",
    "in_degs = ng.in_degrees().float()\n",
    "norm_left = 1 / out_degs\n",
    "norm_right = 1 / in_degs\n",
    "ng.ndata['l_norm'] = norm_left\n",
    "ng.ndata['r_norm'] = norm_right\n",
    "ng.srcdata['h'] = norm_left\n",
    "def copy_x(edges):\n",
    "  return {'ld': edges.dst['h'], 'ls': edges.src['h'], 'rd': edges.dst['r_norm'], 'rs': edges.src['r_norm']} # \"edge.dst\" is the opposite of \"graph.dstdata\"\n",
    "ng.apply_edges(copy_x)\n",
    "print(ng.edata)\n",
    "print(ng.ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out_degs.shape)\n",
    "out_degs.shape + (1,) * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 2 2 2 3]\n",
      "[0 0 1 3 1 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "ng = dgl.graph(([0, 1, 0, 1, 3, 2, 3, 3], [1, 1, 0, 2, 1, 2, 3, 2]), num_nodes=4)\n",
    "tng = dgl.reorder_graph(ng, edge_permute_algo='src')\n",
    "tng = dgl.reorder_graph(tng, edge_permute_algo='dst')\n",
    "ng = tng\n",
    "coo = tng.adjacency_matrix(transpose = True ,scipy_fmt = 'coo')\n",
    "print(coo.row)\n",
    "print(coo.col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_ID': tensor([1, 0, 2, 5, 3, 4, 7, 6]), 'ls': tensor([0.5000, 0.5000, 0.5000, 0.3333, 0.5000, 1.0000, 0.3333, 0.3333]), 'rd': tensor([1.0000, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 1.0000]), 'both': tensor([0.5000, 0.1667, 0.1667, 0.1111, 0.1667, 0.3333, 0.1111, 0.3333])}\n",
      "{'_ID': tensor([0, 1, 2, 3]), 'l_norm': tensor([0.5000, 0.5000, 1.0000, 0.3333]), 'r_norm': tensor([1.0000, 0.3333, 0.3333, 1.0000])}\n"
     ]
    }
   ],
   "source": [
    "# check the left and right norm\n",
    "out_degs = ng.out_degrees().float()\n",
    "in_degs = ng.in_degrees().float()\n",
    "norm_left = 1 / out_degs\n",
    "norm_right = 1 / in_degs\n",
    "ng.ndata['l_norm'] = norm_left\n",
    "ng.ndata['r_norm'] = norm_right\n",
    "def copy_x(edges):\n",
    "  return {'ls': edges.src['l_norm'], 'rd': edges.dst['r_norm'], 'both': edges.src['l_norm'] * edges.dst['r_norm']} # \"edge.dst\" is the opposite of \"graph.dstdata\"\n",
    "ng.apply_edges(copy_x)\n",
    "print(ng.edata)\n",
    "print(ng.ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../trace/model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('TVM_torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcda534459351ecc57fa336edba6dc9ce1979ef7e4ed81f54ba70140eb814979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
