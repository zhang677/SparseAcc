{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfs_data/zhanggh/miniconda3/envs/TVM_torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "from dgl.data import CoraGraphDataset, CiteseerGraphDataset, PubmedGraphDataset\n",
    "from dgl import AddSelfLoop\n",
    "import argparse\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_size, hid_size, out_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        # two-layer GCN\n",
    "        self.layers.append(dglnn.GraphConv(in_size, hid_size, activation=F.relu))\n",
    "        self.layers.append(dglnn.GraphConv(hid_size, out_size))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = features\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                h = self.dropout(h)\n",
    "            h = layer(g, h)\n",
    "        return h\n",
    "    \n",
    "def evaluate(g, features, labels, mask, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "\n",
    "def train(g, features, labels, masks, model):\n",
    "    # define train/val samples, loss function and optimizer\n",
    "    train_mask = masks[0]\n",
    "    val_mask = masks[1]\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        logits = model(g, features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = evaluate(g, features, labels, val_mask, model)\n",
    "        print(\"Epoch {:05d} | Loss {:.4f} | Accuracy {:.4f} \"\n",
    "              . format(epoch, loss.item(), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "Training...\n",
      "Epoch 00000 | Loss 1.9457 | Accuracy 0.2860 \n",
      "Epoch 00001 | Loss 1.9400 | Accuracy 0.1980 \n",
      "Epoch 00002 | Loss 1.9324 | Accuracy 0.2320 \n",
      "Epoch 00003 | Loss 1.9240 | Accuracy 0.3480 \n",
      "Epoch 00004 | Loss 1.9157 | Accuracy 0.5080 \n",
      "Epoch 00005 | Loss 1.9045 | Accuracy 0.6120 \n",
      "Epoch 00006 | Loss 1.8926 | Accuracy 0.6700 \n",
      "Epoch 00007 | Loss 1.8851 | Accuracy 0.6800 \n",
      "Epoch 00008 | Loss 1.8720 | Accuracy 0.6600 \n",
      "Epoch 00009 | Loss 1.8610 | Accuracy 0.6620 \n"
     ]
    }
   ],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "raw_dir = \"../data/dgl\"\n",
    "# load and preprocess dataset\n",
    "transform = AddSelfLoop()\n",
    "data = CoraGraphDataset(raw_dir=raw_dir, transform=transform)\n",
    "g = data[0]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "g = g.int().to(device)\n",
    "features = g.ndata['feat']\n",
    "labels = g.ndata['label']\n",
    "masks = g.ndata['train_mask'], g.ndata['val_mask'], g.ndata['test_mask']\n",
    "    \n",
    "# normalization\n",
    "degs = g.in_degrees().float()\n",
    "norm = torch.pow(degs, -0.5).to(device)\n",
    "norm[torch.isinf(norm)] = 0\n",
    "g.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "# create GCN model    \n",
    "in_size = features.shape[1]\n",
    "out_size = data.num_classes\n",
    "model = GCN(in_size, 16, out_size).to(device)\n",
    "\n",
    "# model training\n",
    "print('Training...')\n",
    "train(g, features, labels, masks, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GraphConv(in=1433, out=16, normalization=both, activation=<function relu at 0x7fba3f8f9af0>)\n",
      "    (1): GraphConv(in=16, out=7, normalization=both, activation=None)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "<class 'dgl.nn.pytorch.conv.graphconv.GraphConv'>\n",
      "both\n",
      "16\n",
      "1433\n",
      "relu\n",
      "tensor([[ 0.0215,  0.0372, -0.0192,  ...,  0.0021, -0.0052, -0.0157],\n",
      "        [ 0.0328,  0.0998, -0.0019,  ...,  0.0361,  0.0914, -0.0276],\n",
      "        [ 0.0335, -0.0006,  0.0153,  ...,  0.0121, -0.0161, -0.1174],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0408,  0.0059,  ...,  0.0235, -0.0238,  0.0362],\n",
      "        [ 0.1194, -0.0027, -0.0152,  ...,  0.0440,  0.0286,  0.0403],\n",
      "        [ 0.0553, -0.0928, -0.0081,  ..., -0.0938, -0.0405,  0.1224]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(model)\n",
    "print(model.layers[0].__class__)\n",
    "print(model.layers[0].__dict__['_norm'])\n",
    "print(model.layers[0].__dict__['_out_feats'])\n",
    "print(model.layers[0].__dict__['_in_feats'])\n",
    "print(model.layers[0].__dict__['_activation'].__name__)\n",
    "print(model.layers[0].state_dict()['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enlarge_feature(g):\n",
    "    from math import log2, pow\n",
    "    shape = g.ndata['feat'].shape\n",
    "    feat_num = pow(2,int(log2(shape[1])) + 1)\n",
    "    g.ndata['feat'] = F.pad(g.ndata['feat'], (0,int(feat_num-shape[1])), \"constant\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 4096])\n",
      "torch.Size([2708, 4096])\n"
     ]
    }
   ],
   "source": [
    "tmp_g = g\n",
    "enlarge_feature(tmp_g)\n",
    "print(tmp_g.ndata['feat'].shape)\n",
    "print(g.ndata['feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feat', 'label', 'test_mask', 'train_mask', 'val_mask', 'norm'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('TVM_torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcda534459351ecc57fa336edba6dc9ce1979ef7e4ed81f54ba70140eb814979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
